* Similarity search vs semantic search in vector databases. Vector databases are based on similarity search, but what we really want is semantic search for relevant contents. [[vector databases]]
[[https://news.ycombinator.com/item?id=37420628][LLMs, RAG, and the missing storage layer for AI | Hacker News]]
#+BEGIN_QUOTE
The first unstated assumption is that similar vectors are relevant documents, and for many use cases that's just not true. Cosine similarity != relevance. So if your pipeline pulls 2 or 4 or 12 document chunks into the LLM's context, and half or more of them aren't relevant, does this make the LLM's response more or less relevant?

The second unstated assumption is that the vector index can accurately identify the top K vectors by cosine similarity, and that's not true either. If you retrieve the top K vectors according to the vector index (instead of computing all the pairwise similarities in advance), that set of 10 vectors will be missing documents that have a higher cosine similarity than that of the K'th vector retrieved.

All of this means you'll need to retrieve a multiple of K vectors, figure out some way to re-rank them to exclude the irrelevant ones, and have your own ground truth to measure the index's precision and recall. 
#+END_QUOTE
*